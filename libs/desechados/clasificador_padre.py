# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kKjQo3SPzPgEL81LK1XqmPBOxK-Bv-Gd
"""


"""
El sistema esta pensado para que definas bloques Data_in, h0, h1, h2, h3... hn, Data_out.
De modo que en hardcode se definen que capas usar, pero la cantidad de neuronas de cada capa,
quedan libres para modificarlas cuando se llama constructor de la clase medinte el vector architecture. 
Despues, clases es un vector, donde los indices mapean a la label de lo que se quiere clasificar.
"""

import torch as torch
from torch import nn
from torchvision import datasets
from torchvision.transforms import ToTensor
from tqdm import tqdm
import torchaudio

class _Clasificador_padre(nn.Module):
  def __init__(self, classes):
    """Hijo, necesito que generes una arquitectura"""
    super().__init__()
    self.classes = classes.copy()
    self.name = "JonDoe"
    
  def forward(self):
    """Hijo, no entiendo como recorrer tu arquitectura"""
    """Lo unico que te pido es que devuelvas un Tensor"""
    pass

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    loss_acum = 0
    accuracy_acum = 0
    b = 1
    for input_batch, target_batch in data_loader:
      #datos a la GPU o CPU (segun lo que me pasaron)
      input_batch = input_batch.to(device)
      target_batch = target_batch.to(device)
      #prediccion y optimizacion
      optimizer.zero_grad()
      prediccion = self(input_batch)
      loss = loss_fn(prediccion, target_batch)
      loss.backward()
      optimizer.step()
      #metricas
      with torch.no_grad():
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
        #if b % 10 == 0:
        #  print(f"Data: {b*len(input_batch)}/ {len(data_loader*len(input_batch))}")
    #Calculo de la media de las metricas
    with torch.no_grad():
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
    return loss_acum, accuracy_acum

  def train_loop(self, epochs, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    self.train()
    loss_list = torch.empty(0)
    accuracy_list = torch.empty(0)
    for epoch in range(epochs):
      new_loss, new_accuracy = self._train_epoch(data_loader, optimizer, loss_fn, acuracy_fn, device)
      #Guardo la metrica
      with torch.no_grad():
        loss_list.resize_(epoch + 1) #agrego un espacio para el loss que acabo de calcular
        loss_list[- 1] = new_loss #inserto el loss nuevo en el lugar que le cree en la linea de arriba
        accuracy_list.resize_(epoch + 1)
        accuracy_list[- 1] = new_accuracy
        print(f"Epoch {epoch} of {epochs} / Loss: {loss_list[-1]} / Accuracy: {accuracy_list[-1]}")
    return loss_list, accuracy_list

  def evaluate(self, data_loader, loss_fn, acuracy_fn, device):
    """
    """
    self.eval()
    with torch.no_grad():
      loss_acum = 0
      accuracy_acum = 0
      for input_batch, target_batch in tqdm(data_loader):
        input_batch = input_batch.to(device)
        target_batch = target_batch.to(device)
        
        #prediccion y optimizacion
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        #metricas
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
      #Calculo de la media de las metricas
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
      return loss_acum, accuracy_acum

  def classes(self):
    """
    Devuelve una lista con las clases del modelo
    """
    return self.classes.copy()

  def save_model(self, fname):
    """
    Esta funcion guarda un modelo que se guardo con un formato específico, el cual corresponde a el state_dict de una red neuronal al que se le agrega un
    campo que indica la arquitectura de la red "architecture" y un campo que indica las clases del modelo "classes"

    Args:
      modelo: Modelo a guardar
      name: Nombre del archivo destino

    Returns:
      saveState: diccionario guardado en el archivo
    """
    saveState = modelo.state_dict()
    saveState['classes'] = modelo.classes()
    torch.save(saveState, f"{self.name}_{fname}")
    return None

def load_model_file(l_file):
  """
  Esta funcion carga un modelo que se guardo con un formato específico, el cual corresponde a el state_dict de una red neuronal al que se le agrega un
  campo que indica la arquitectura de la red "architecture" y un campo que indica las clases del modelo "classes"

  Args:
    l_file: Nombre del archivo destino

  Returns:
    Clases del modelo cargado
    Parametros del modelo cargado
  """
  saveState = torch.load(l_file)
  classes = saveState.pop('classes')
  return classes, saveState

class Clasificador_01(_Clasificador_padre):
  def __init__(self, classes, load = False, architecture = []):
    super().__init__()
    #Variables de entorno
    self.name = "clas_01"
    self.classes = classes
    
    #Capas de la arquitectura
    if load :
      self.architecture = architecture
    else:
      architecture = [[1,16,3,1,2],
                      [1,16,3,1,2],
                      [16,32,3,1,2],
                      [1032,500],
                      [500,3]
                      ]
    
    #Baloques de la red
    self.inPut = nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 2),
        #nn.Conv2d(*architecture[0]),
        nn.Conv1d(kernel_size=3, in_channels=430, out_channels=430, stride=1, groups=430),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 5)
    )
    self.hide = []
    
    #self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #    nn.Conv2d(*architecture[1]),
    #    nn.ReLU(),
    #    nn.MaxPool2d(kernel_size= 5)
    #))
    
    #self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #    nn.Conv2d(*architecture[2]),
    #    nn.ReLU(),
    #    nn.MaxPool2d(kernel_size= 2)
    #))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Flatten(start_dim= 1),
        nn.Dropout(0.5),
        nn.Linear(*architecture[3]),
        nn.ReLU(),
    ))  
    
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(*architecture[-1]), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1)
            #Cambiamos la salida a una distribucion de probabilidad
    )

  def forward(self, x):
    #print("In:", x.shape)       
    x=x.permute(0,2,1) #pongo el tiempo en el eje para conv 1D
    #print("In:", x.shape)       
    prediccion = self.inPut(x)
    #print("Shape post 1D: ", prediccion.shape)
    x=x.permute(0,2,1) #recupero los ejes
    prediccion = prediccion.unsqueeze(1) #agrego canal 1 para las prediction
    #print("Shape post unsqueeze: ", prediccion.shape)
    for layer in self.hide:
      prediccion = layer(prediccion)
      #print(prediccion.shape)         ######################################################################
    prediccion = self.out(prediccion)
    return  prediccion



class Clasificador_02(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Capas de la arquitectura
    self.architecture = [[1,4,3,1,2],
                    [4,8,3,1,2],
                    [8,16,5,1,2],
                    [16,32,5,3,2],
                    [32,64,7,3,2],
                    [1536,750],
                    [750,375],
                    [375,125],
                    [125,3]
                    ] 
    #Baloques de la red
    self.inPut = nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 2),
        nn.Conv2d(*self.architecture[0]),
        nn.ReLU() )
    self.hide = []
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Conv2d(*self.architecture[1]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Dropout(0.5),
        nn.Conv2d(*self.architecture[2]),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 2) ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Dropout(0.5),
        nn.Conv2d(*self.architecture[3]),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 2) ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Conv2d(*self.architecture[4]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Flatten(start_dim= 1),
        nn.Dropout(0.5),
        nn.Linear(*self.architecture[5]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Flatten(start_dim= 1),
        nn.Dropout(0.5),
        nn.Linear(*self.architecture[6]),
        nn.ReLU() ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Flatten(start_dim= 1),
        nn.Linear(*self.architecture[7]),
        nn.ReLU()  ))  
    
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(*self.architecture[-1]), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))

  def forward(self, x):
    #print("In:", x.shape)       
    #x=x.permute(0,2,1) #pongo el tiempo en el eje para conv 1D
    #print("In:", x.shape)       
    x = x.unsqueeze(1)
    prediccion = self.inPut(x)
    #print("Shape post 1D: ", prediccion.shape)
    #x=x.permute(0,2,1) #recupero los ejes
    #prediccion = prediccion.unsqueeze(1) #agrego canal 1 para las prediction
    #print("Shape post unsqueeze: ", prediccion.shape)
    for layer in self.hide:
      prediccion = layer(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = self.out(prediccion)
    print("Alive")
    return  prediccion


class Clasificador_03(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Capas de la arquitectura
    self.architecture = [[1,4,3,1,2],
                    [4,8,3,1,2],
                    [8,16,5,1,2],
                    [16,32,5,3,2],
                    [32,64,7,3,2],
                    [1536,750],
                    [750,375],
                    [375,125],
                    [125,3]
                    ] 
    #Baloques de la red
    self.inPut = nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 2),
        nn.Conv2d(*self.architecture[0]),
        nn.ReLU() )
    self.hide = []
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Conv2d(*self.architecture[1]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Dropout(0.5),
        nn.Conv2d(*self.architecture[2]),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 2) ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Dropout(0.5),
        nn.Conv2d(*self.architecture[3]),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 2) ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Conv2d(*self.architecture[4]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Flatten(start_dim= 1),
        #nn.Dropout(0.5),
        nn.Linear(*self.architecture[5]),
        nn.ReLU()  ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Flatten(start_dim= 1),
        #nn.Dropout(0.5),
        nn.Linear(*self.architecture[6]),
        nn.ReLU() ))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Flatten(start_dim= 1),
        nn.Linear(*self.architecture[7]),
        nn.ReLU()  ))  
    
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(*self.architecture[-1]), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))

  def forward(self, x):
    #print("In:", x.shape)       
    #x=x.permute(0,2,1) #pongo el tiempo en el eje para conv 1D
    #print("In:", x.shape)       
    x = x.unsqueeze(1)
    prediccion = self.inPut(x)
    #print("Shape post 1D: ", prediccion.shape)
    #x=x.permute(0,2,1) #recupero los ejes
    #prediccion = prediccion.unsqueeze(1) #agrego canal 1 para las prediction
    #print("Shape post unsqueeze: ", prediccion.shape)
    for layer in self.hide:
      prediccion = layer(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = self.out(prediccion)
    print("Alive")
    return  prediccion

class onlyWoman_MFCC_01(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Capas de la arquitectura
    self.architecture = [[1,4,3,1,2],
                    [4,16,(1,7),1,0],
                    [16,32,(1,7),1,0],
                    [32,64,(1,7),(1,2),0],
                    [64,64,(3,7),(1,2),0],
                    [64,64,(3,7),(1,2),0],
                    [19712,1000],
                    [1000,500],
                    [500,100],
                    [100,10],
                    [10,3],

                    ] 
    #Baloques de la red
    
    _i = 0
    self.inPut = nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 2),
        nn.Conv2d(*self.architecture[_i]),
        nn.ReLU() )
    _i = _i+1
    self.hide = []

    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #nn.Dropout(0.5),
    nn.Conv2d(*self.architecture[_i]),
    nn.ReLU()))
    #nn.MaxPool2d(kernel_size= 2) ))
    _i = _i+1

    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #nn.Dropout(0.5),
    nn.Conv2d(*self.architecture[_i]),
    nn.ReLU()))
    _i = _i+1

    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #nn.Dropout(0.5),
    nn.Conv2d(*self.architecture[_i]),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size= (1,2)) ))
    _i = _i+1

    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #nn.Dropout(0.5),
    nn.Conv2d(*self.architecture[_i]),
    nn.ReLU()))
    _i = _i+1

    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Conv2d(*self.architecture[_i]),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= (1,2)) ))
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(*self.architecture[-5]), #Lineal que sale a las clases objetivo
        nn.Linear(*self.architecture[-4]), #Lineal que sale a las clases objetivo
        nn.Linear(*self.architecture[-3]), #Lineal que sale a las clases objetivo
        nn.Linear(*self.architecture[-2]), #Lineal que sale a las clases objetivo
        nn.Linear(*self.architecture[-1]), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)       
    #x=x.permute(0,2,1) #pongo el tiempo en el eje para conv 1D
    #print("In:", x.shape)       
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    #print("Shape post 1D: ", prediccion.shape)
    #x=x.permute(0,2,1) #recupero los ejes
    #prediccion = prediccion.unsqueeze(1) #agrego canal 1 para las prediction
    #print("Shape post unsqueeze: ", prediccion.shape)
    for layer in self.hide:
      prediccion = layer(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    #print("Alive")
    return  prediccion


class onlyWoman_MFCC_02(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      #nn.Dropout(0.5),
      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),

      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)) 
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(19712,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_02_N1(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),

      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(19712,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_02_N2(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),

      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(19712,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion



class onlyWoman_MFCC_04_N2(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),

      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(19712,1500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1500,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_05_N2(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.BatchNorm2d(4),
      nn.ReLU(),


      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),


      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(19712,1500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1500,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion

class onlyWoman_MFCC_16k(onlyWoman_MFCC_05_N2):
  def __init__(self, classes, MFCC_transforemr = None):
    super().__init__(classes)
    self.transformer = MFCC_transforemr
    self.name = "MFCC_16k"


  def forward(self, x):
    #print("In:", x.shape)            
    if(self.transformer != None):
      x = self.transformer(x)
    #print("Transformed:", x.shape)
    prediccion = super().forward(x)
    #x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    #prediccion = self.inPut(x)
    #prediccion = self.chanelUp(prediccion)
    #prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    #prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    #prediccion = self.out(prediccion)
    #print("prediccion:", prediccion.shape)
    return  prediccion

class onlyWoman_MFCC_16k_v2(onlyWoman_MFCC_05_N2):
  def __init__(self, classes, MFCC_transforemr = None):
    super().__init__(classes)
    self.transformer = MFCC_transforemr
    self.name = "MFCC_16k"


  def forward(self, x):
    #print("In:", x.shape)            
    if(self.transformer != None):
      x = self.transformer(x)
    #print("Transformed:", x.shape)
    prediccion = super().forward(x)
    #x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    #prediccion = self.inPut(x)
    #prediccion = self.chanelUp(prediccion)
    #prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    #prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    #prediccion = self.out(prediccion)
    #print("prediccion:", prediccion.shape)
    return  prediccion

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    loss_acum = 0
    accuracy_acum = 0
    b = 1
    for input_batch, target_batch, rir_batch in data_loader:
      #datos a la GPU o CPU (segun lo que me pasaron)
      input_batch = input_batch.to(device)
      target_batch = target_batch.to(device)
      rir_batch = rir_batch.to(device)
      #convoluciono la entrada con el rir
      input_batch = torchaudio.functional.fftconvolve(input_batch, rir_batch, "full") #[:input_batch.shape[1]]
      input_batch = input_batch[:,:160000]
        #print("Input_batch:",input_batch.shape)
      #normalizo la senial del rir
      max_abs_val = input_batch.abs().max(dim = 1, keepdim = True)[0]
        #print("max_abs: ", max_abs_val.shape)
      input_batch = input_batch / max_abs_val
        #print("normalized input_batch:", input_batch.shape)
      #prediccion y optimizacion
      optimizer.zero_grad()
      prediccion = self(input_batch)
      loss = loss_fn(prediccion, target_batch)
      loss.backward()
      optimizer.step()
      #metricas
      with torch.no_grad():
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
        #if b % 10 == 0:
        #  print(f"Data: {b*len(input_batch)}/ {len(data_loader*len(input_batch))}")
      #Calculo de la media de las metricas
    with torch.no_grad():
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
    return loss_acum, accuracy_acum  

  def evaluate(self, data_loader, loss_fn, acuracy_fn, device):
    """
    """
    self.eval()
    with torch.no_grad():
      loss_acum = 0
      accuracy_acum = 0
      for input_batch, target_batch, _ in tqdm(data_loader):
        input_batch = input_batch.to(device)
        target_batch = target_batch.to(device)
        
        #prediccion y optimizacion
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        #metricas
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
      #Calculo de la media de las metricas
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
      return loss_acum, accuracy_acum

class onlyWoman_MFCC_T(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,(1,2)),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      #nn.Dropout(0.5),
      nn.Conv2d(4,4,(1,3),1,0),
      nn.ReLU(),
      nn.Conv2d(4,16,(1,7),1,0),
      nn.ReLU(),

      #nn.Conv2d(16,16,(1,5),1,0),
      #nn.ReLU(),
      nn.Conv2d(16,32,(1,7),1,0),
      nn.ReLU(),
      
      #nn.Conv2d(32,32,(1,7),1,0),
      #nn.ReLU(),
      nn.Conv2d(32,64,(1,7),1,0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)) 
      )

    self.extract =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),
      #nn.Conv2d(64,64,(3,7),(1,2),0),
      #nn.ReLU(),
      #nn.Conv2d(64,64,(3,7),(1,2),0),
      #nn.ReLU(),
      nn.Conv2d(64,32,(3,7),(1,2),0),
      nn.ReLU(),
      nn.Conv2d(32,16,(3,7),(1,2),0),
      nn.ReLU())
      #nn.MaxPool2d(kernel_size= (2,2)) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(6272,512), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(512,32), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(32,16), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(16,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x, v = False):
    if v:
      #print("In:", x.shape)            
      x = x.unsqueeze(1)
      print("squeeze:", x.shape)
      prediccion = self.inPut(x)
      print("post 1x1:", x.shape)
      prediccion = self.chanelUp(prediccion)
      print("post chanelUp:", prediccion.shape)
      prediccion = self.extract(prediccion)
      print("post extract:", prediccion.shape)
      prediccion = torch.flatten(prediccion,1)
      print("post flatten:", prediccion.shape)
      prediccion = self.out(prediccion)
    else:
      x = x.unsqueeze(1)
      prediccion = self.inPut(x)
      prediccion = self.chanelUp(prediccion)
      prediccion = self.extract(prediccion)
      prediccion = torch.flatten(prediccion,1)
      prediccion = self.out(prediccion)
    return  prediccion


##########################################################
#####  Variacion de chanel up ##################
#########################################

class onlyWoman_MFCC_base(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.BatchNorm2d(4),
      nn.ReLU(),


      nn.Conv2d(4,8,(1,3),1,0),
      nn.ReLU(),


      nn.Conv2d(8,16,(1,5),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(16,32,(1,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(5,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(64,64,(5,7),(1,2),0),
      nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(64) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(2240,1500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1500,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_16k_v3(onlyWoman_MFCC_base):
  def __init__(self, classes, MFCC_transforemr = None):
    super().__init__(classes)
    self.transformer = MFCC_transforemr
    self.name = "MFCC_16k"


  def forward(self, x):
    #print("In:", x.shape)            
    if(self.transformer != None):
      x = self.transformer(x)
    #print("Transformed:", x.shape)
    prediccion = super().forward(x)
    #x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    #prediccion = self.inPut(x)
    #prediccion = self.chanelUp(prediccion)
    #prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    #prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    #prediccion = self.out(prediccion)
    #print("prediccion:", prediccion.shape)
    return  prediccion

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    loss_acum = 0
    accuracy_acum = 0
    b = 1
    for input_batch, target_batch, rir_batch in data_loader:
      #datos a la GPU o CPU (segun lo que me pasaron)
      input_batch = input_batch.to(device)
      target_batch = target_batch.to(device)
      rir_batch = rir_batch.to(device)
      #convoluciono la entrada con el rir
      input_batch = torchaudio.functional.fftconvolve(input_batch, rir_batch, "full") #[:input_batch.shape[1]]
      input_batch = input_batch[:,:160000]
        #print("Input_batch:",input_batch.shape)
      #normalizo la senial del rir
      max_abs_val = input_batch.abs().max(dim = 1, keepdim = True)[0]
        #print("max_abs: ", max_abs_val.shape)
      input_batch = input_batch / max_abs_val
        #print("normalized input_batch:", input_batch.shape)
      #prediccion y optimizacion
      optimizer.zero_grad()
      prediccion = self(input_batch)
      loss = loss_fn(prediccion, target_batch)
      loss.backward()
      optimizer.step()
      #metricas
      with torch.no_grad():
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
        #if b % 10 == 0:
        #  print(f"Data: {b*len(input_batch)}/ {len(data_loader*len(input_batch))}")
      #Calculo de la media de las metricas
    with torch.no_grad():
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
    return loss_acum, accuracy_acum  

  def evaluate(self, data_loader, loss_fn, acuracy_fn, device):
    """
    """
    self.eval()
    with torch.no_grad():
      loss_acum = 0
      accuracy_acum = 0
      for input_batch, target_batch, _ in tqdm(data_loader):
        input_batch = input_batch.to(device)
        target_batch = target_batch.to(device)
        
        #prediccion y optimizacion
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        #metricas
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
      #Calculo de la media de las metricas
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
      return loss_acum, accuracy_acum


########################################################
######### V4  ########################
#####################################

class onlyWoman_MFCC_base_2(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.BatchNorm2d(4),
      nn.ReLU(),


      nn.Conv2d(4,8,(1,3),1,0),
      nn.ReLU(),


      nn.Conv2d(8,16,(1,5),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(16,32,(1,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.Conv2d(64,128,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(128)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(128,256,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(256,512,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(512,512,(5,7),(1,2),0),
      nn.ReLU(),

      #nn.Conv2d(128,128,(5,7),(1,2),0),
      #nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(512) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(3584,3584), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(3584,1500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1500,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_16k_v4(onlyWoman_MFCC_base_2):
  def __init__(self, classes, MFCC_transforemr = None):
    super().__init__(classes)
    self.transformer = MFCC_transforemr
    self.name = "MFCC_16k"


  def forward(self, x):
    #print("In:", x.shape)            
    if(self.transformer != None):
      x = self.transformer(x)
    #print("Transformed:", x.shape)
    prediccion = super().forward(x)
    #x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    #prediccion = self.inPut(x)
    #prediccion = self.chanelUp(prediccion)
    #prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    #prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    #prediccion = self.out(prediccion)
    #print("prediccion:", prediccion.shape)
    return  prediccion

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    loss_acum = 0
    accuracy_acum = 0
    b = 1
    for input_batch, target_batch, rir_batch in data_loader:
      #datos a la GPU o CPU (segun lo que me pasaron)
      input_batch = input_batch.to(device)
      target_batch = target_batch.to(device)
      rir_batch = rir_batch.to(device)
      #convoluciono la entrada con el rir
      input_batch = torchaudio.functional.fftconvolve(input_batch, rir_batch, "full") #[:input_batch.shape[1]]
      input_batch = input_batch[:,:160000]
        #print("Input_batch:",input_batch.shape)
      #normalizo la senial del rir
      max_abs_val = input_batch.abs().max(dim = 1, keepdim = True)[0]
        #print("max_abs: ", max_abs_val.shape)
      input_batch = input_batch / max_abs_val
        #print("normalized input_batch:", input_batch.shape)
      #prediccion y optimizacion
      optimizer.zero_grad()
      prediccion = self(input_batch)
      loss = loss_fn(prediccion, target_batch)
      loss.backward()
      optimizer.step()
      #metricas
      with torch.no_grad():
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
        #if b % 10 == 0:
        #  print(f"Data: {b*len(input_batch)}/ {len(data_loader*len(input_batch))}")
      #Calculo de la media de las metricas
    with torch.no_grad():
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
    return loss_acum, accuracy_acum  

  def evaluate(self, data_loader, loss_fn, acuracy_fn, device):
    """
    """
    self.eval()
    with torch.no_grad():
      loss_acum = 0
      accuracy_acum = 0
      for input_batch, target_batch, _ in tqdm(data_loader):
        input_batch = input_batch.to(device)
        target_batch = target_batch.to(device)
        
        #prediccion y optimizacion
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        #metricas
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
      #Calculo de la media de las metricas
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
      return loss_acum, accuracy_acum


########################################################
######### V5  ########################
#####################################

class onlyWoman_MFCC_base_5(_Clasificador_padre):
  def __init__(self, classes):
    super().__init__(classes)
    self.name = "clas_02"
    #Variables de entorno
    ###
    #Baloques de la red
    self.inPut = nn.Sequential( 
        nn.Conv2d(1,4,3,1,2),
        nn.ReLU() )

    self.chanelUp =  nn.Sequential(
      nn.BatchNorm2d(4),
      nn.ReLU(),


      nn.Conv2d(4,8,(1,3),1,0),
      nn.ReLU(),


      nn.Conv2d(8,16,(1,5),1,0),
      nn.ReLU(),
      
      #nn.Dropout(0.5),
      nn.Conv2d(16,32,(1,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(32,64,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.Conv2d(64,128,(1,7),(1,2),0),
      nn.ReLU(),
      
      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(128)
      )

    self.justTime =  nn.Sequential( #bloque que recibe los datos y los acondiciona
      #nn.Dropout(0.5),
      nn.Conv2d(128,256,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(256,512,(3,7),(1,2),0),
      nn.ReLU(),

      nn.Conv2d(512,512,(5,7),(1,2),0),
      nn.ReLU(),

      #nn.Conv2d(128,128,(5,7),(1,2),0),
      #nn.ReLU(),

      nn.MaxPool2d(kernel_size= (1,2)),
      nn.BatchNorm2d(512) )
 
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(3584,3584), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(3584,3000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(3000,1500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1500,1000), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(1000,500), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(500,100), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(100,10), #Lineal que sale a las clases objetivo
        nn.ReLU(),
        nn.Linear(10,3), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1))


  def forward(self, x):
    #print("In:", x.shape)            
    x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    prediccion = self.inPut(x)
    prediccion = self.chanelUp(prediccion)
    prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    prediccion = self.out(prediccion)
    return  prediccion


class onlyWoman_MFCC_16k_v5(onlyWoman_MFCC_base_2):
  def __init__(self, classes, MFCC_transforemr = None):
    super().__init__(classes)
    self.transformer = MFCC_transforemr
    self.name = "MFCC_16k"


  def forward(self, x):
    #print("In:", x.shape)            
    if(self.transformer != None):
      x = self.transformer(x)
    #print("Transformed:", x.shape)
    prediccion = super().forward(x)
    #x = x.unsqueeze(1)
    #print("squeeze:", x.shape)
    #prediccion = self.inPut(x)
    #prediccion = self.chanelUp(prediccion)
    #prediccion = self.justTime(prediccion)
    #  print(prediccion.shape)         ######################################################################
    #prediccion = torch.flatten(prediccion,1)
    #print("post flatten:", prediccion.shape)
    #prediccion = self.out(prediccion)
    #print("prediccion:", prediccion.shape)
    return  prediccion

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn, device):
    """
    + El data_loader debe retornar primero el input y segundo el target
    + El acuracy_fn debe retornar un tensor
    + Acurracy_fn debe poder recibir una prediccion en formato Tensor y un target en formato Tensor
    """
    loss_acum = 0
    accuracy_acum = 0
    b = 1
    for input_batch, target_batch, rir_batch in data_loader:
      #datos a la GPU o CPU (segun lo que me pasaron)
      input_batch = input_batch.to(device)
      target_batch = target_batch.to(device)
      rir_batch = rir_batch.to(device)
      #convoluciono la entrada con el rir
      input_batch = torchaudio.functional.fftconvolve(input_batch, rir_batch, "full") #[:input_batch.shape[1]]
      input_batch = input_batch[:,:160000]
        #print("Input_batch:",input_batch.shape)
      #normalizo la senial del rir
      max_abs_val = input_batch.abs().max(dim = 1, keepdim = True)[0]
        #print("max_abs: ", max_abs_val.shape)
      input_batch = input_batch / max_abs_val
        #print("normalized input_batch:", input_batch.shape)
      #prediccion y optimizacion
      optimizer.zero_grad()
      prediccion = self(input_batch)
      loss = loss_fn(prediccion, target_batch)
      loss.backward()
      optimizer.step()
      #metricas
      with torch.no_grad():
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
        #if b % 10 == 0:
        #  print(f"Data: {b*len(input_batch)}/ {len(data_loader*len(input_batch))}")
      #Calculo de la media de las metricas
    with torch.no_grad():
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
    return loss_acum, accuracy_acum  

  def evaluate(self, data_loader, loss_fn, acuracy_fn, device):
    """
    """
    self.eval()
    with torch.no_grad():
      loss_acum = 0
      accuracy_acum = 0
      for input_batch, target_batch, _ in tqdm(data_loader):
        input_batch = input_batch.to(device)
        target_batch = target_batch.to(device)
        
        #prediccion y optimizacion
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        #metricas
        loss_acum += loss.item()
        accuracy_acum += acuracy_fn(prediccion, target_batch)
      #Calculo de la media de las metricas
      accuracy_acum /= len(data_loader)
      loss_acum /= len(data_loader)
      return loss_acum, accuracy_acum
