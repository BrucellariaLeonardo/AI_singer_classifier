# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kKjQo3SPzPgEL81LK1XqmPBOxK-Bv-Gd
"""


"""
El sistema esta pensado para que definas bloques Data_in, h0, h1, h2, h3... hn, Data_out.
De modo que en hardcode se definen que capas usar, pero la cantidad de neuronas de cada capa,
quedan libres para modificarlas cuando se llama constructor de la clase medinte el vector architecture. 
Despues, clases es un vector, donde los indices mapean a la label de lo que se quiere clasificar.
"""

import torch as torch
from torch import nn
from torchvision import datasets
from torchvision.transforms import ToTensor

class Clasificador_01(nn.Module):
  def __init__(self, classes, load = False, architecture = []):
    super().__init__()
    #Variables de entorno
    self.name = "clas_01"
    self.classes = classes
    
    #Capas de la arquitectura
    if load :
      self.architecture = architecture
    else:
      architecture = [[1,16,3,1,2],
                      [1,16,3,1,2],
                      [16,32,3,1,2],
                      [1032,500],
                      [500,3]
                      ]
    
    #Baloques de la red
    self.inPut = nn.Sequential( #bloque que recibe los datos y los acondiciona
        #nn.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 2),
        #nn.Conv2d(*architecture[0]),
        nn.Conv1d(kernel_size=3, in_channels=430, out_channels=430, stride=1, groups=430),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size= 5)
    )
    self.hide = []
    
    #self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #    nn.Conv2d(*architecture[1]),
    #    nn.ReLU(),
    #    nn.MaxPool2d(kernel_size= 5)
    #))
    
    #self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
    #    nn.Conv2d(*architecture[2]),
    #    nn.ReLU(),
    #    nn.MaxPool2d(kernel_size= 2)
    #))
    
    self.hide.append( nn.Sequential( #bloque que recibe los datos y los acondiciona
        nn.Flatten(start_dim= 1),
        nn.Dropout(0.5),
        nn.Linear(*architecture[3]),
        nn.ReLU(),
    ))  
    
    self.out = nn.Sequential(   # bloque que acondiciona la salida
        nn.Linear(*architecture[-1]), #Lineal que sale a las clases objetivo
        nn.Softmax( dim = 1)
            #Cambiamos la salida a una distribucion de probabilidad
    )

  def forward(self, x):
    #print("In:", x.shape)       
    x=x.permute(0,2,1) #pongo el tiempo en el eje para conv 1D
    #print("In:", x.shape)       
    prediccion = self.inPut(x)
    #print("Shape post 1D: ", prediccion.shape)
    x=x.permute(0,2,1) #recupero los ejes
    prediccion = prediccion.unsqueeze(1) #agrego canal 1 para las prediction
    #print("Shape post unsqueeze: ", prediccion.shape)
    for layer in self.hide:
      prediccion = layer(prediccion)
      #print(prediccion.shape)         ######################################################################
    prediccion = self.out(prediccion)
    return  prediccion

  def predict(self, input):
    """
    Esta funcion recibe un dato y genera una prediccion en forma de a que clase puede pertenecer

    Args:
      input: Tensor en el mismo dispositivo que el modelo
      WARNING: Asegurate de que tanto los datos como el modelo esten en el mismo dispositivo antes de llamar al metodo

    Returns:
      class_name: Nombre de la clase mas probable
      confidence: Probabilidad de la clase
    """
    #self.eval()
    with torch.no_grad():
      prediction = self(input)[0]   #llamado a forward para obtener vector de probabilidades de clase
      index = prediction.argmax()   #obtenencion del indice de la clase mas probable
      class_name = self.classes[index]  #traduccion de indice a el nombre de la clase
      confidence = prediction[index]    #probabilidad de la clase elegida
    return class_name, confidence

  def _train_epoch(self, data_loader, optimizer, loss_fn, acuracy_fn):
      """
      + El data_loader debe retornar primero el input y segundo el target
      + El acuracy_fn debe retornar un vector convertible a tensoor
      """
      loss_acum = []
      accuracy_acum = []
      for input_batch, target_batch in data_loader:
        #prediccion y optimizacion
        #self.train()
        prediccion = self(input_batch)
        loss = loss_fn(prediccion, target_batch)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        #metricas
        #self.eval()
        with torch.no_grad():
          loss_acum.append(loss.item())
          accuracy_acum.append(acuracy_fn(prediccion, target_batch))  #accuracy_list.append((prediccion.argmax(dim=1) == targets).float().mean())
      return torch.tensor(loss_acum).mean() , torch.tensor(accuracy_acum).mean()

  def train(self, epochs, data_loader, optimizer, loss_fn, acuracy_fn):
    """
    """
    loss_list = []
    accuracy_list = []
    for epoch in range(epochs):
      loss, accuracy = self._train_epoch(data_loader, optimizer, loss_fn, acuracy_fn)
      loss_list.append(loss)
      accuracy_list.append(accuracy)
      print(f"Epoch {epoch} of {epochs} / Loss: {loss_list[-1]} / Accuracy: {accuracy_list[-1]}")
    return loss_list, accuracy_list
  def classes(self):
    """
    Devuelve una lista con las clases del modelo
    """
    return self.classes.copy()
  def architecture(self):
    """
    Devuelve una lista con la arquitectura del modelo
    """
    return self.architecture.copy()

def save_model(modelo, name):
  """
  Esta funcion guarda un modelo que se guardo con un formato específico, el cual corresponde a el state_dict de una red neuronal al que se le agrega un
  campo que indica la arquitectura de la red "architecture" y un campo que indica las clases del modelo "classes"

  Args:
    modelo: Modelo a guardar
    name: Nombre del archivo destino

  Returns:
    saveState: diccionario guardado en el archivo
  """
  saveState = modelo.state_dict()
  saveState['architecture'] = modelo.architecture()
  saveState['classes'] = modelo.classes()
  torch.save(saveState, f"{self.name}_{name}")
  return saveState

def load_model(name, constructor):
  """
  Esta funcion carga un modelo que se guardo con un formato específico, el cual corresponde a el state_dict de una red neuronal al que se le agrega un
  campo que indica la arquitectura de la red "architecture" y un campo que indica las clases del modelo "classes"

  Args:
    name: Nombre del archivo destino
    constructor: Constructor de la red neuronal que se va a cargar

  Returns:
    Modelo cargado
    Arquitectura del modelo cargado
    Clases del modelo cargado
    Parametros del modelo cargado
  """
  saveState = torch.load(name)
  architecture = saveState.pop('architecture')
  classes = saveState.pop('classes')
  modelo = constructor(classes, load = True, architecture = architecture)
  modelo.load_state_dict(saveState)
  return modelo, architecture, classes, saveState


class Clasificador_02(Clasificador):
  def __init__(self, classes, load = False, architecture = []):
    super().__init__(classes, load, architecture)
    self.name = "clas_02"