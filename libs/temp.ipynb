{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef1bb34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m(torch.argmax(target_batch, axis=\u001b[32m1\u001b[39m) == torch.argmax(prediccion, axis=\u001b[32m1\u001b[39m)).sum().item() / \u001b[38;5;28mlen\u001b[39m(target_batch)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Add the 'libs' directory to sys.path to allow direct imports\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m script_dir = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m     49\u001b[39m libs_dir = os.path.abspath(os.path.join(script_dir, \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibs\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m libs_dir \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys.path:\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d7b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys # Add sys import\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import sounddevice as sd # Removed: from importlib.machinery import SourceFileLoader\n",
    "import pandas as pd\n",
    "\n",
    "def check_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "def search_for_data():\n",
    "    root = '.'\n",
    "        #set the root path in the data folder\n",
    "    while not os.path.isdir(os.path.join(root,\"data\")):\n",
    "        root = os.path.join(root,\"..\")\n",
    "    return root\n",
    "\n",
    "def gen_df_paths():\n",
    "    Path_train = os.path.join(root,'data',dataSetName+'_train.csv')\n",
    "    Path_val = os.path.join(root,'data',dataSetName+'_val.csv')\n",
    "    Path_test = os.path.join(root,'data',dataSetName+'_test.csv')\n",
    "    return Path_train, Path_val, Path_test\n",
    "\n",
    "def mem_usage(tensor):\n",
    "    \"\"\"Reurns in Gb\"\"\"\n",
    "    return tensor.element_size() * tensor.nelement() / (1024**3)\n",
    "\n",
    "def fn_test_data_loader(DataLoader):\n",
    "    for train_features,target,rir in tqdm(train_dataloader):\n",
    "        pass\n",
    "    print(train_features.shape)\n",
    "    print(f\"Batch mem usage: {mem_usage(train_features)+ mem_usage(target)+ mem_usage(rir)}\")\n",
    "\n",
    "def acuracy_fn (prediccion, target_batch):\n",
    "    return(torch.argmax(target_batch, axis=1) == torch.argmax(prediccion, axis=1)).sum().item() / len(target_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14660373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add the 'libs' directory to sys.path to allow direct imports\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m script_dir = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m      3\u001b[39m libs_dir = os.path.abspath(os.path.join(script_dir, \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibs\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m libs_dir \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys.path:\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add the 'libs' directory to sys.path to allow direct imports\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#libs_dir = os.path.abspath(os.path.join(script_dir, '..', 'libs'))\n",
    "#if libs_dir not in sys.path:\n",
    "#    sys.path.insert(0, libs_dir)\n",
    "\n",
    "# Import modules using their filenames\n",
    "import dataLoaders_16k as DataSetLib # Assumes dataLoaders_16k.py is in ../libs\n",
    "import clasificador_padreV2 as ModelLib # Assumes clasificador_padreV2.py is in ../libs\n",
    "\n",
    "DataSetConst = DataSetLib.DataSet_song_plus_rir_v4\n",
    "ModelConst = ModelLib.onlyWoman_MFCC_16k_v8\n",
    "\n",
    "\n",
    "#Metaparameters for MFCC transformer\n",
    "#parametros para los calculos del mell\n",
    "TARGET_SR = 16000  # Normalmente el audio se sule usar a 16k aunque encontre papers que trabajan a 22050 o a 22k (ver V2)\n",
    "N_FFT = 1024  #muestras de la fft\n",
    "W_LEN = 800  # Numero de muestras para la ventan de la  fft (seg_de_ventan *sr) \n",
    "H_LEN = 320 # paso de la ventana entre una fft y la siguiente (paso * sr)\n",
    "N_MELS = 40#26\n",
    "N_MFCC = 32#13\n",
    "MFCCCalculator = torchaudio.transforms.MFCC(sample_rate = TARGET_SR,\n",
    "                                            n_mfcc = int(N_MFCC),\n",
    "                                            dct_type = 2,\n",
    "                                            norm = 'ortho',\n",
    "                                            log_mels = False,\n",
    "                                            melkwargs = \n",
    "                                            {\n",
    "                                                \"n_fft\": N_FFT,          # Size of FFT (2048)\n",
    "                                                \"win_length\": W_LEN,     # Actual window size (400 samples = 25ms)\n",
    "                                                \"hop_length\": H_LEN,     # Hop length (160 samples = 10ms)\n",
    "                                                \"n_mels\": N_MELS,        # Number of Mel bins (40)\n",
    "                                                \"center\": False\n",
    "                                                },)\n",
    "\n",
    "#Check for device\n",
    "device = check_device()\n",
    "print(\"Device:\", device)\n",
    "#Root params\n",
    "dataSetName = '16k_songs'\n",
    "root = search_for_data()\n",
    "\n",
    "#Paths of the df (DATASET)\n",
    "Path_train, Path_val, Path_test = gen_df_paths()\n",
    "#list of the data augmentation files\n",
    "Path_rir = os.path.join(root,\"data\",\"RIR_16K\")\n",
    "Path_noise = os.path.join(root,\"data\",\"NOISE_16K\")\n",
    "#Load of the data frames\n",
    "trainDf = pd.read_csv(Path_train)\n",
    "testDf = pd.read_csv(Path_test)\n",
    "valDf = pd.read_csv(Path_val)\n",
    "\n",
    "#Carga del data Loader\n",
    "trainDataSet = DataSetConst(trainDf, \"16k_file\", \"artist\", Path_rir, os.listdir(Path_rir), rir_prob = 0.5, seed = 98)\n",
    "train_dataloader = DataLoader(trainDataSet, batch_size= 128,\n",
    "                                shuffle=True, num_workers= 2,\n",
    "                                pin_memory=True, drop_last=True)\n",
    "#fn_test_data_loader(train_dataloader)    \n",
    "\n",
    "#instanciando el modelo\n",
    "\n",
    "os.listdir('./save/state')\n",
    "pState = \"./save/state/\"\n",
    "pHist = \"./save/history/\"\n",
    "overWrite = False\n",
    "show_metrics = True\n",
    "sLoad = -1 #save state a cargar\n",
    "lr = 0.0001\n",
    "weight_decay= 0.005\n",
    "\n",
    "MFCCCalculator.to(device)\n",
    "clasificador = ModelConst(list(trainDataSet.dictionary.keys()), MFCCCalculator)\n",
    "clasificador.to(device)\n",
    "#print(clasificador)\n",
    "\n",
    "\n",
    "\n",
    "if((len(os.listdir(pState)) == 0) or overWrite):\n",
    "    history = {}\n",
    "    history['loss'] = torch.empty(0)\n",
    "    history['acur'] = torch.empty(0)\n",
    "\n",
    "else:\n",
    "    history =  torch.load(pHist+os.listdir(pHist)[sLoad])\n",
    "\n",
    "    save_state = torch.load(pState+os.listdir(pState)[sLoad])\n",
    "    clasificador.load_state_dict(save_state)\n",
    "\n",
    "test_optimizer = torch.optim.Adam(clasificador.parameters(), lr=lr, weight_decay= weight_decay)\n",
    "test_criterion = torch.nn.CrossEntropyLoss()\n",
    "print(clasificador.modules)\n",
    "\n",
    "if show_metrics:\n",
    "    plt.ion()\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize = (6,6))\n",
    "    l1, = axes[0].plot([], [])\n",
    "    l2, = axes[1].plot([], [])\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Acur')\n",
    "\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c946284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    clasificador.train()\n",
    "    for j in tqdm(range(10)):\n",
    "        for i in range(2):\n",
    "            loss_log, acur_log = clasificador.train_loop(1,train_dataloader, test_optimizer , test_criterion, acuracy_fn, device)\n",
    "            history['loss'] = torch.cat((history['loss'], loss_log), dim=0)\n",
    "            history['acur'] = torch.cat((history['acur'], acur_log), dim=0)\n",
    "            \n",
    "            if show_metrics:\n",
    "                # Grafica\n",
    "                l1.set_data(range(len(history['acur'])), history['acur'])\n",
    "                axes[0].relim()  # Recalculate data limits\n",
    "                axes[0].autoscale_view()  # Rescale axes\n",
    "\n",
    "                l2.set_data(range(len(history['loss'])), history['loss'])\n",
    "                axes[1].relim()  # Recalculate data limits\n",
    "                axes[1].autoscale_view()  # Rescale axes\n",
    "                \n",
    "                fig.canvas.draw()  # Redraw the figure\n",
    "                fig.canvas.flush_events()  # Ensure events are processed\n",
    "                plt.pause(0.5)\n",
    "\n",
    "        save_state = clasificador.state_dict()\n",
    "        n = len(os.listdir(pState))\n",
    "        #Guardo con dos digitos para asegurarme que no se desordena el indice a la hora de llamar a listdir para cargar el modelo\n",
    "        if(n < 10):\n",
    "            torch.save(save_state, f\"{pState}/ss_0{n}.pt\") \n",
    "            torch.save(history, f\"{pHist}/hist_0{n}.pt\")\n",
    "        else:\n",
    "            torch.save(save_state, f\"{pState}/ss_{n}.pt\")\n",
    "            torch.save(history, f\"{pHist}/hist_{n}.pt\")\n",
    "\n",
    "    if show_metrics:\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "    #modo evaluacion\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    clasificador.eval()\n",
    "    valDataSet = DataSetConst(valDf, \"16k_file\", \"artist\", Path_rir, os.listdir(Path_rir), rir_prob = 0.7, seed = 98)\n",
    "    val_dataloader = DataLoader(valDataSet, batch_size= 128,\n",
    "                                shuffle=True, num_workers= 2,\n",
    "                                pin_memory=True, drop_last=True)\n",
    "\n",
    "    val_histo = []\n",
    "    max_acur = 0\n",
    "    mejor = None\n",
    "    mejor_name = None\n",
    "    for ss_name in tqdm(os.listdir(f\"{pState}/\")):\n",
    "        ss_load = torch.load(f\"{pState}{ss_name}\")\n",
    "        clasificador.load_state_dict(ss_load)\n",
    "        resultado_evalucion = clasificador.evaluate(val_dataloader, loss_fn, acuracy_fn, device)\n",
    "        val_histo.append(resultado_evalucion)\n",
    "        if resultado_evalucion[1] > max_acur:\n",
    "            max_acur = resultado_evalucion[1]\n",
    "            mejor = ss_load\n",
    "            mejor_name = ss_name\n",
    "    print(val_histo)\n",
    "    print(\"\")\n",
    "    print(\"Mejor:\", mejor_name)\n",
    "    print(\"Acur:\", max_acur)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
